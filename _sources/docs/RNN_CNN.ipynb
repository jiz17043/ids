{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a69c3c5",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network\n",
    "\n",
    "- DLP/NN: deal\n",
    "- CNN: capture the spatial data structure(image analysis)\n",
    "- RNN: capture the sequential data structure(sentence, stock price)\n",
    "\n",
    "**Example** : \"I like eating apple.\" and \"Apple is a company.\". If we want to specify different meanings of a word, we need to take the nearby words into consideration.\n",
    "\n",
    "How does RNN works:\\\n",
    "The hidden layer remembers the infomation of the previous hidden layer $h_{t-1}$, and then learn from the current data $X_t$.\n",
    "![Recurrent_neural_network_unfold.svg](attachment:Recurrent_neural_network_unfold.svg)\n",
    "$$\n",
    "O_t=g(Wh_t)\\\\\n",
    "h_t=f(UX_t+Vh_{t-1})\n",
    "$$\n",
    "- $X_t$: input vector\n",
    "- $h_t$: hidden layer vector\n",
    "- $O_t$: output vector\n",
    "- $W,U,V$: parameter matrices\n",
    "\n",
    "**Example** Assume we have trained a RNN, 2 nodes with weights $W,U,V=(0.5,0.5)'$, our sequence \n",
    "$(1,1)',(1,2)',...$\\\n",
    "$h_1=(0.5*1+0.5*1,0.5*1+0.5*1)=(1,1),O_1=(1,1)$\\\n",
    "$h_2=(0.5*1+0.5*2,0.5*1+0.5*2)+(1,1)=(2.5,2.5),O_2=(2.5,2.5)$\n",
    "\n",
    "LSTM: \"long short term memory\", a commonly used RNN model.\n",
    "\n",
    "\n",
    "```python\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "# define documents\n",
    "docs = ['Well done!',\n",
    "        'Good work',\n",
    "        'Great effort',\n",
    "        'nice work',\n",
    "        'Excellent!',\n",
    "        'Weak',\n",
    "        'Poor effort!',\n",
    "        'not good',\n",
    "        'poor work',\n",
    "        'Could have done better.']\n",
    "# define class labels\n",
    "labels = array([1,1,1,1,1,0,0,0,0,0])\n",
    "\n",
    "# integer encode the documents\n",
    "vocab_size = 50\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "print(encoded_docs)\n",
    "```\n",
    "\n",
    "    [[16, 1], [46, 17], [5, 10], [35, 17], [27], [2], [4, 10], [40, 46], [4, 17], [26, 41, 1, 6]]\n",
    "    \n",
    "\n",
    "\n",
    "```python\n",
    "e = Embedding(200, 32, input_length=50)\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))\n",
    "```\n",
    "\n",
    "    [[16  1  0  0]\n",
    "     [46 17  0  0]\n",
    "     [ 5 10  0  0]\n",
    "     [35 17  0  0]\n",
    "     [27  0  0  0]\n",
    "     [ 2  0  0  0]\n",
    "     [ 4 10  0  0]\n",
    "     [40 46  0  0]\n",
    "     [ 4 17  0  0]\n",
    "     [26 41  1  6]]\n",
    "    Model: \"sequential_1\"\n",
    "    _________________________________________________________________\n",
    "     Layer (type)                Output Shape              Param #   \n",
    "    =================================================================\n",
    "     embedding_1 (Embedding)     (None, 4, 8)              400       \n",
    "                                                                     \n",
    "     flatten_1 (Flatten)         (None, 32)                0         \n",
    "                                                                     \n",
    "     dense_2 (Dense)             (None, 1)                 33        \n",
    "                                                                     \n",
    "    =================================================================\n",
    "    Total params: 433\n",
    "    Trainable params: 433\n",
    "    Non-trainable params: 0\n",
    "    _________________________________________________________________\n",
    "    None\n",
    "    Accuracy: 89.999998\n",
    "    \n",
    "\n",
    "# Convolutional Neural Network\n",
    "\n",
    "## Filter\n",
    "Filter is also known as kernel. It is a designed matrix in CNN, which extracts the local features from a data.\n",
    "\n",
    "## Basic concepts\n",
    "- Padding: Addition of (typically) 0-valued pixels on the borders of an image\n",
    "- Pooling: Reduce the dimensions of data by combining the outputs of previous neuron into a single neuron in the next layer.\n",
    "- Channels: Number of filters in a layer\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "```\n",
    "\n",
    "    Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "    170500096/170498071 [==============================] - 123s 1us/step\n",
    "    170508288/170498071 [==============================] - 123s 1us/step\n",
    "    \n",
    "\n",
    "\n",
    "```python\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "```\n",
    "\n",
    "\n",
    "```python\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "    Model: \"sequential\"\n",
    "    _________________________________________________________________\n",
    "     Layer (type)                Output Shape              Param #   \n",
    "    =================================================================\n",
    "     conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
    "                                                                     \n",
    "     max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
    "     )                                                               \n",
    "                                                                     \n",
    "     conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
    "                                                                     \n",
    "     max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
    "     2D)                                                             \n",
    "                                                                     \n",
    "     conv2d_2 (Conv2D)           (None, 4, 4, 64)          36928     \n",
    "                                                                     \n",
    "    =================================================================\n",
    "    Total params: 56,320\n",
    "    Trainable params: 56,320\n",
    "    Non-trainable params: 0\n",
    "    _________________________________________________________________\n",
    "    \n",
    "\n",
    "The input data is $32*32*3$ tensor, and the layers are:\n",
    "- Conv layer: $3*3$ filter, channels=32\n",
    "- Pooling layer: $2*2$ maxpooling\n",
    "- Conv layer: $3*3$ filter, channels=64\n",
    "- Pooling layer: $2*2$ maxpooling\n",
    "- Conv layer: $3*3$ filter, channels=64\n",
    "\n",
    "\n",
    "```python\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "    Model: \"sequential\"\n",
    "    _________________________________________________________________\n",
    "     Layer (type)                Output Shape              Param #   \n",
    "    =================================================================\n",
    "     conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
    "                                                                     \n",
    "     max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
    "     )                                                               \n",
    "                                                                     \n",
    "     conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
    "                                                                     \n",
    "     max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
    "     2D)                                                             \n",
    "                                                                     \n",
    "     conv2d_2 (Conv2D)           (None, 4, 4, 64)          36928     \n",
    "                                                                     \n",
    "     flatten (Flatten)           (None, 1024)              0         \n",
    "                                                                     \n",
    "     dense (Dense)               (None, 64)                65600     \n",
    "                                                                     \n",
    "     dense_1 (Dense)             (None, 10)                650       \n",
    "                                                                     \n",
    "    =================================================================\n",
    "    Total params: 122,570\n",
    "    Trainable params: 122,570\n",
    "    Non-trainable params: 0\n",
    "    _________________________________________________________________\n",
    "    \n",
    "\n",
    "To complete model, the last layer(dense layer) outputs the 1-dimensional vector to make a classification.\n",
    "\n",
    "[See the picture here](https://www.google.com/url?sa=i&url=https%3A%2F%2Ftowardsdatascience.com%2Fa-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53&psig=AOvVaw0X2854QLmfCfvXO8Lj5eC9&ust=1637352332958000&source=images&cd=vfe&ved=0CAsQjRxqFwoTCID77_naovQCFQAAAAAdAAAAABAD)\n",
    "\n",
    "\n",
    "```python\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=10, \n",
    "                    validation_data=(test_images, test_labels))\n",
    "```\n",
    "\n",
    "    Epoch 1/10\n",
    "    1563/1563 [==============================] - 59s 37ms/step - loss: 1.5502 - accuracy: 0.4321 - val_loss: 1.3032 - val_accuracy: 0.5331\n",
    "    Epoch 2/10\n",
    "    1563/1563 [==============================] - 58s 37ms/step - loss: 1.2001 - accuracy: 0.5765 - val_loss: 1.1816 - val_accuracy: 0.5806\n",
    "    Epoch 3/10\n",
    "    1563/1563 [==============================] - 54s 34ms/step - loss: 1.0436 - accuracy: 0.6316 - val_loss: 1.0422 - val_accuracy: 0.6347\n",
    "    Epoch 4/10\n",
    "    1563/1563 [==============================] - 54s 35ms/step - loss: 0.9299 - accuracy: 0.6737 - val_loss: 0.9405 - val_accuracy: 0.6712\n",
    "    Epoch 5/10\n",
    "    1563/1563 [==============================] - 55s 35ms/step - loss: 0.8501 - accuracy: 0.7027 - val_loss: 0.9336 - val_accuracy: 0.6752\n",
    "    Epoch 6/10\n",
    "    1563/1563 [==============================] - 55s 35ms/step - loss: 0.7862 - accuracy: 0.7249 - val_loss: 0.8879 - val_accuracy: 0.6898\n",
    "    Epoch 7/10\n",
    "    1563/1563 [==============================] - 55s 35ms/step - loss: 0.7354 - accuracy: 0.7414 - val_loss: 0.8518 - val_accuracy: 0.7038\n",
    "    Epoch 8/10\n",
    "    1563/1563 [==============================] - 57s 36ms/step - loss: 0.6873 - accuracy: 0.7593 - val_loss: 0.8349 - val_accuracy: 0.7101\n",
    "    Epoch 9/10\n",
    "    1563/1563 [==============================] - 56s 36ms/step - loss: 0.6497 - accuracy: 0.7722 - val_loss: 0.8684 - val_accuracy: 0.7094\n",
    "    Epoch 10/10\n",
    "    1563/1563 [==============================] - 56s 36ms/step - loss: 0.6069 - accuracy: 0.7865 - val_loss: 0.8711 - val_accuracy: 0.7054\n",
    "    \n",
    "\n",
    "\n",
    "```python\n",
    "print(test_acc)\n",
    "```\n",
    "\n",
    "    0.7053999900817871"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.13.0"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "source_map": [
   12
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}