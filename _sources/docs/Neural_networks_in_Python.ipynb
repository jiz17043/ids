{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0707c6f",
   "metadata": {},
   "source": [
    "# Neural Networks in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80986b0",
   "metadata": {},
   "source": [
    "## What is a Neural Network?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c63f375",
   "metadata": {},
   "source": [
    "In these notes we will be implementing a predictive Neural Network in Python. Artificial Neural Networks are a specific type of machine learning model loosely based on the Biological Neural Networks that our own brains run on. Neural Networks have seen extremely broad applications including but not limited to pattern recognition, medical diagnostics, geosciences, cybersecurity, and quantum chemistry.\n",
    "\n",
    "At their core, Neural Networks consist of the following:\n",
    "\n",
    "\n",
    "\n",
    "- An input layer, $x$\n",
    "- An arbitrary amount of **hidden layers** comprised of nodes which process data from previous layers\n",
    "- An output layer, $\\hat{y}$\n",
    "- A set of **weights** and **biases** connecting the nodes in each layer, $W$ and $b$\n",
    "- An **activation function** for each hidden layer, $\\sigma$, which takes the layers' input and outputs a value between 0 and 1 (or -1 and 1).  \n",
    "\n",
    "These layers act to progressively extract higher level features from raw input in a process known as Deep Learning (so long as there is more than two hidden layers). A simplified diagram of a Neural Network is shown below. You can see the input layer on the left which is inputted into the hidden layer in the middle, which outputs to the output layer and classifies the image.\n",
    "\n",
    "![Neural Network simplified diagram](https://miro.medium.com/max/1080/1*36MELEhgZsPFuzlZvObnxA.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d3bc8b",
   "metadata": {},
   "source": [
    "There can be any number of hidden layers and nodes in each layer, and multiple different activation functions (linear, sigmoid, etc.) can be used. Part of the challenge of successfully implementing a Neural Network is determining these things."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680fcae6",
   "metadata": {},
   "source": [
    "## Training a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267ceee9",
   "metadata": {},
   "source": [
    "Another key part of a neural network is its ability to self train. Commonly this is done in two steps that are repeated until the desired performance is achieved.\n",
    "- Calculating the predicted output $\\hat{y}$, called **feedforward**\n",
    "- Updating the weights $W$ and biases $b$, called **backpropogation**\n",
    "\n",
    "This allows Neural Networks to learn so long as they have already classified data to be trained on. An diagram of what this looks like with a one layer Neural Network is shown below. Here we can see the input $x$, as well as the weights $W$ and biases $b$ used at the start which are used to _feedforward_ and get the $\\hat{y}$. Then the weights and biases are updated based on the derivative of the loss function.\n",
    "\n",
    "![feedforward and backpropogation](https://miro.medium.com/max/700/1*CEtt0h8Rss_qPu7CyqMTdQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f52f0ea",
   "metadata": {},
   "source": [
    "Generally training a Neural Network will occur over **Epochs** split into **Batches**. An Epoch is one pass through all rows of the training dataset. A Batch is one (or more) samples considered by the model within an epoch before updating weights (backpropogation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81be8219",
   "metadata": {},
   "source": [
    "## Keras: A Python Module for Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5c7fa6",
   "metadata": {},
   "source": [
    "Keras is a versatile module for python to implement neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49191f1",
   "metadata": {},
   "source": [
    "### Install Keras:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c03224",
   "metadata": {},
   "source": [
    "Please install package below beforehand and dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1676d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install keras\n",
    "#!pip3 install tensorflow\n",
    "#!pip3 install uszipcode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e59d8f1",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c81da81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "from uszipcode import SearchEngine\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acd04b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"kaggle/input/train_2021.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0319239e",
   "metadata": {},
   "source": [
    "This dataset has a number of non-numeric variables that need to be properly processed first. This is borrowed from a previous version of my group's Travelers competition work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d466dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.marital_status.fillna(1.0, inplace = True)    # fill the five values with majority\n",
    "train.witness_present_ind.fillna(0.0, inplace = True)  # fill with majority as well as witness not present when na\n",
    "train.age_of_vehicle.fillna(5, inplace = True)\n",
    "\n",
    "input_mod1 = linear_model.LinearRegression()\n",
    "input_mod1.fit(train.loc[train.claim_est_payout.isna() == False, ['vehicle_price', 'age_of_vehicle']],\n",
    "               train.claim_est_payout[train.claim_est_payout.isna() == False])\n",
    "\n",
    "# predicted values for NA's\n",
    "input_output = pd.Series(input_mod1.predict(train.loc[train.claim_est_payout.isna() == True,\n",
    "                                                      ['vehicle_price', 'age_of_vehicle']]),\n",
    "                         index = train.index[train.claim_est_payout.isna()==True])\n",
    "\n",
    "train.claim_est_payout.fillna(input_output, inplace = True)\n",
    "\n",
    "train['claim_date_d'] = pd.Series([datetime.datetime.strptime(d, '%m/%d/%Y').strftime('%d')\n",
    "                                   for d in train.claim_date], index = train.index)\n",
    "train['claim_date_m'] = pd.Series([datetime.datetime.strptime(d, '%m/%d/%Y').strftime('%m')\n",
    "                                   for d in train.claim_date], index = train.index)\n",
    "\n",
    "# Capping 'age_of_driver' at 80\n",
    "train['age_of_driver'] = train['age_of_driver'].clip(upper = 80)\n",
    "\n",
    "# fitting regression of claim_est_payout using vehicle_price and `age_of_vehicle`\n",
    "\n",
    "input_mod2 = linear_model.LinearRegression()\n",
    "input_mod2.fit(train.loc[train.annual_income != -1, ['age_of_driver']],\n",
    "               train.annual_income[train.annual_income != -1])\n",
    "\n",
    "# predicted values for -1's\n",
    "input_output2 = pd.Series(input_mod2.predict(train.loc[train.annual_income == -1,\n",
    "                                                      ['age_of_driver']]),\n",
    "                         index = train.index[train.annual_income == -1])\n",
    "\n",
    "# replacing -1 values with predicted values\n",
    "train.annual_income.replace(to_replace = ([-1] * len(input_output2)), \n",
    "                            value = input_output2, inplace = True)\n",
    "\n",
    "engine = SearchEngine()\n",
    "\n",
    "def zip_lookup(row):\n",
    "    if row.zip_code == 0:\n",
    "        return pd.DataFrame(data = {\n",
    "                \"state\" : [np.nan],\n",
    "                \"lat\" : [np.nan],\n",
    "                \"lng\" : [np.nan]\n",
    "               })\n",
    "    else:\n",
    "        info = engine.by_zipcode(str(row.zip_code))\n",
    "        # changing to pandas dataframe\n",
    "        return pd.DataFrame(data = {\n",
    "                \"state\" : [info.state],\n",
    "                \"lat\" : [info.lat],\n",
    "                \"lng\" : [info.lng]\n",
    "               })\n",
    "    \n",
    "train[\"state\"] = train.apply(lambda row: zip_lookup(row).at[0, 'state'], axis = 1)\n",
    "train[\"latitude\"] = train.apply(lambda row: zip_lookup(row).at[0, 'lat'], axis = 1)\n",
    "train[\"longitude\"] = train.apply(lambda row: zip_lookup(row).at[0, 'lng'], axis = 1)\n",
    "\n",
    "train[\"state\"] = train.state.fillna(method = \"bfill\")\n",
    "train[\"latitude\"] = train.latitude.fillna(method = \"bfill\")\n",
    "train[\"longitude\"] = train.longitude.fillna(method = \"bfill\")\n",
    "\n",
    "train_encoded = pd.DataFrame()\n",
    "\n",
    "# modify all numerical to binned variables\n",
    "train_encoded['claim_number'] = train['claim_number'].astype('category')\n",
    "train_encoded['dr_age_bins'] = pd.cut(train.age_of_driver, \n",
    "                                      bins = train.age_of_driver.quantile([0, .05, .25, .75, .95, 1]), \n",
    "                                      include_lowest = True)\n",
    "train_encoded['dr_safty_bins'] = pd.cut(train.safty_rating,\n",
    "                                        bins = train.safty_rating.quantile([0, .1, .3, .8, .95, 1]), \n",
    "                                        include_lowest = True)\n",
    "train_encoded['dr_annual_income'] = pd.cut(train.annual_income, \n",
    "                                           bins = train.annual_income.quantile([0, .1, .3, .8, .95, 1]),\n",
    "                                           include_lowest = True)\n",
    "train_encoded['zip_code_1'] = round(train.zip_code/10000, 0).astype('category')    # satisfy the same state\n",
    "train_encoded['past_num_of_claims'] = pd.cut(train.past_num_of_claims,\n",
    "                                             bins = train.past_num_of_claims.quantile([0, 0.8, 0.9, 1]),\n",
    "                                             include_lowest = True) # ordinal\n",
    "train_encoded['liab_prct'] = pd.cut(train.liab_prct, \n",
    "                                    bins = train.liab_prct.quantile([0, 0.25, 0.75, 1]),\n",
    "                                    include_lowest = True)\n",
    "train_encoded['claim_est_payout'] = pd.cut(train.claim_est_payout,\n",
    "                                           bins = train.claim_est_payout.quantile([0, 0.05, .25, .75, .95, 1]),\n",
    "                                           include_lowest = True)\n",
    "train_encoded['age_of_vehicle'] = pd.cut(train.age_of_vehicle,\n",
    "                                         bins = train.age_of_vehicle.quantile([0, .25, .75, .9, 1]),\n",
    "                                         include_lowest = True)\n",
    "train_encoded['vehicle_price'] = pd.cut(train.vehicle_price,\n",
    "                                        bins = train.vehicle_price.quantile([0, .1, .25, .75, .9, 1]),\n",
    "                                        include_lowest = True)\n",
    "train_encoded['vehicle_weight'] = pd.cut(train.vehicle_weight,\n",
    "                                         bins = train.vehicle_weight.quantile([0, .1, .25, .75, .9, 1]),\n",
    "                                         include_lowest = True)\n",
    "\n",
    "# not binned numeric\n",
    "train_encoded['latitude'] = train['latitude']\n",
    "train_encoded['longitude'] = train['longitude']\n",
    "\n",
    "\n",
    "# derived variables as categorical\n",
    "# train_encoded['claim_date_d'] = train['claim_date_d'].astype('category')\n",
    "# train_encoded['claim_date_m'] = train['claim_date_m'].astype('category')\n",
    "\n",
    "# already categorical variables\n",
    "train_encoded['gender'] = train['gender']\n",
    "train_encoded['marital_status'] = train['marital_status'].astype('category')\n",
    "train_encoded['high_education_ind'] = train['high_education_ind'].astype('category')\n",
    "train_encoded['address_change_ind'] = train['address_change_ind'].astype('category')\n",
    "train_encoded['living_status'] = train['living_status']\n",
    "train_encoded['claim_day_of_week'] = train['claim_day_of_week']\n",
    "train_encoded['witness_present_ind'] = train['witness_present_ind'].astype('category')\n",
    "train_encoded['channel'] = train['channel']\n",
    "train_encoded['policy_report_filed_ind'] = train['policy_report_filed_ind'].astype('category')\n",
    "train_encoded['vehicle_category'] = train['vehicle_category']\n",
    "train_encoded['vehicle_color'] = train['vehicle_color']\n",
    "train_encoded['state'] = train['state'].astype('category')\n",
    "train_encoded['fraud'] = train['fraud'].astype('category')\n",
    "\n",
    "list_ordinal = ['dr_safty_bins', 'dr_annual_income', 'past_num_of_claims','liab_prct',\n",
    "                'claim_est_payout', 'age_of_vehicle', 'vehicle_price', 'vehicle_weight']\n",
    "list_other = ['dr_age_bins', 'zip_code_1', 'gender', 'marital_status', 'high_education_ind',\n",
    "              'address_change_ind', 'living_status', 'claim_day_of_week', \n",
    "              'witness_present_ind', 'channel', 'policy_report_filed_ind', 'vehicle_category',\n",
    "              'vehicle_color', 'state']\n",
    "\n",
    "encoding = [('ord', OrdinalEncoder(), list_ordinal), ('cat', OneHotEncoder(), list_other)]\n",
    "# encoding = [('ord', OneHotEncoder(), list_ordinal), ('cat', OneHotEncoder(), list_other)]\n",
    "col_transform = ColumnTransformer(transformers = encoding)\n",
    "\n",
    "X = train_encoded.iloc[:, 1:-1]\n",
    "y = train_encoded.iloc[:,  -1]\n",
    "\n",
    "X_1 = col_transform.fit_transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_in1, X_hold1, y_in, y_hold = train_test_split(X_1, y, test_size=0.3, random_state=341)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03067875",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_in1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb0e273",
   "metadata": {},
   "source": [
    "### Defining the Keras Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6c7096",
   "metadata": {},
   "source": [
    "As discussed previously, Neural Networks are defined as a sequence of layers. In this example we will be creating a _Sequential model_ where we will add one layer at a time until we are satisfied with the network structure. This is done by defining a new model using the `Sequential()` class from Keras.  \n",
    "  \n",
    "Knowing how many layers to add and their structure is a challenging problem, and is often best solved through trial and error. Though generally a Neural Network should be large enough to reflect the structure of the problem. In this example we will be using a fully connected structure (Each layers' nodes connect to every node in the layers behind and ahead of them) with 5 layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1985eb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b190d57",
   "metadata": {},
   "source": [
    "Now we will add our layers. Our input layer will be defined in the same command as our first hidden layer. This input layer will have a number of input features (nodes) equal to the number of input variables we have, in this case 57. We do this with the `input_dim` argument when adding our first layer.  \n",
    "  \n",
    "We will add a layer to our model using the `.add()` method. For a fully connected structure we need to use the `Dense()` class. The first argument for `Dense()` specifies the number of nodes in that layer. The `activation` argument tells the network which activation function to use in that layer.  \n",
    "  \n",
    "For activation functions in the hidden layers we will be using the *rectified linear unit activation function* (relu) which is fairly common.  \n",
    "  \n",
    "With that out of the way lets define our first layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63755f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(86, input_dim = 57, activation = \"relu\"))\n",
    "model.add(Dense(57, activation = \"relu\"))\n",
    "model.add(Dense(28, activation = \"relu\"))\n",
    "model.add(Dense(14, activation = \"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8941c0",
   "metadata": {},
   "source": [
    "Now all that's left is to define our output layer. Since this is a classification problem our output layer will have only 1 node, as we only are looking for a single output. We will also use a *sigmoid* activation function instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c547fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f31312f",
   "metadata": {},
   "source": [
    "### Compiling the Keras Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4577e8",
   "metadata": {},
   "source": [
    "Now the model must be compiled using the `.compile()` method. When doing so we must also define a few things relating to the training of the network:\n",
    "- The loss function: This is used to specify how we will evaluate our network during training, defined with the `loss` argument\n",
    "- The optimizer: How our network will optimize itself, defined with the `optimizer` argument\n",
    "- The metrics: Any other metrics we want the model to output, defined with the `metrics` argument as a list\n",
    "\n",
    "In this example we will use `\"binary_crossentropy\"` as our loss function since this is a classification problem. For an optimizer we will use the stochastic gradient descent algorithm `\"adam\"`. Finally as a metric we will add `\"BinaryAccuracy\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f43d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"BinaryAccuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511318b2",
   "metadata": {},
   "source": [
    "### Fitting the Keras Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f65a395",
   "metadata": {},
   "source": [
    "To fit our network model, we will use the `.fit()` method. Doing so we must specify the number of _epochs_ we will iterate through, as well as the size of each _batch_ within each epoch. These are defined using the `epochs` and `batch_size` arguments within this method.  \n",
    "  \n",
    "For this example lets use 100 epochs with a batch size of 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d26020",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_in1, y_in, epochs = 100, batch_size = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a640c8",
   "metadata": {},
   "source": [
    "If you find the reporting on each individual epoch too much, you can always add in `verbose = 0` as an argument to prevent it from doing so."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f7e636",
   "metadata": {},
   "source": [
    "### Evaluating the Keras Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aa8107",
   "metadata": {},
   "source": [
    "Now that we have trained our Neural Network, we can test it on our test data. We will do this using the `.evaluate()` method. Because of how we compiled our model, this will output both the results of the loss function and the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fca4531",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_hold1, y_hold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad46dba",
   "metadata": {},
   "source": [
    "### Making Predictions using the Keras Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad898652",
   "metadata": {},
   "source": [
    "We can also use the model to get predictions using the `.predict()` method. This will output a numpy array of the probabilities for each row, which we could either round (as we do here) or pass through some threshold to get our results. Here we do so on our split test data and create a confusion table to see how well we did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b888670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_hold1)\n",
    "y_pred_r =[round(x[0]) for x in y_pred] \n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(y_hold, y_pred_r))\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee861dc",
   "metadata": {},
   "source": [
    "This isn't necessarily the best result, there is likely some issues with how the input data was handled and the structure of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3458ee",
   "metadata": {},
   "source": [
    "### F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1c128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "round(f1_score(y_hold, y_pred_r), 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6203166",
   "metadata": {},
   "source": [
    "Citations: \n",
    "\n",
    "- Towards Datascience. (2018, May 17). Neural Networks [Gif]. How to Build Your Own Neural Network from Scratch in Python. https://miro.medium.com/max/2400/1*36MELEhgZsPFuzlZvObnxA.gif\n",
    "- Towards Datascience. (2018b, May 17). Sequential Graph [Graph]. How to Build Your Own Neural Network from Scratch in Python. https://miro.medium.com/max/933/1*CEtt0h8Rss_qPu7CyqMTdQ.png"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.12.0"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   13,
   17,
   21,
   39,
   43,
   47,
   57,
   61,
   65,
   69,
   73,
   77,
   81,
   85,
   101,
   103,
   107,
   249,
   251,
   255,
   261,
   263,
   273,
   278,
   282,
   284,
   288,
   297,
   299,
   303,
   309,
   311,
   315,
   319,
   323,
   325,
   329,
   333,
   339,
   343,
   347,
   351
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}